{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMiR4etlvCK4G+e7CZAMpu7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SlySlayer32/Kidsmessyroom/blob/main/Kid_Room_Cleanup_Object_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "14miLxp9bezY"
      },
      "outputs": [],
      "source": [
        "# =====================================\n",
        "# STEP 1: Install Dependencies\n",
        "# =====================================\n",
        "!pip install ultralytics\n",
        "!pip install segment-anything-py\n",
        "!pip install roboflow\n",
        "!pip install opencv-python\n",
        "!pip install pillow\n",
        "!pip install pandas\n",
        "!pip install matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================\n",
        "# STEP 2: Import Libraries\n",
        "# =====================================\n",
        "import cv2\n",
        "import numpy as np\n",
        "from ultralytics import YOLO\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "import json\n",
        "\n",
        "print(\"‚úÖ All libraries imported successfully!\")"
      ],
      "metadata": {
        "id": "hfK2Scepbs8K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================\n",
        "# STEP 3: Load YOLOv8 Model\n",
        "# =====================================\n",
        "# Load the pre-trained YOLOv8 model (you can use yolov8n, yolov8s, yolov8m, yolov8l, yolov8x)\n",
        "model = YOLO('yolov8n.pt')  # 'n' = nano (fastest, smallest)\n",
        "\n",
        "print(\"‚úÖ YOLOv8 model loaded successfully!\")"
      ],
      "metadata": {
        "id": "5Wtu5SSMbzWq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================\n",
        "# STEP 4: Object Detection & Cataloging Function\n",
        "# =====================================\n",
        "def detect_and_catalog_objects(image_path, confidence_threshold=0.25):\n",
        "    \"\"\"\n",
        "    Detect all objects in an image and create a catalog with counts.\n",
        "    Perfect for messy rooms with many scattered items.\n",
        "    \"\"\"\n",
        "    # Read image\n",
        "    image = cv2.imread(image_path)\n",
        "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Run detection\n",
        "    results = model(image_path, conf=confidence_threshold)\n",
        "\n",
        "    # Extract detection data\n",
        "    detections = []\n",
        "    for result in results:\n",
        "        boxes = result.boxes\n",
        "        for box in boxes:\n",
        "            x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()\n",
        "            conf = box.conf[0].cpu().numpy()\n",
        "            cls = int(box.cls[0].cpu().numpy())\n",
        "            class_name = model.names[cls]\n",
        "\n",
        "            detections.append({\n",
        "                'class': class_name,\n",
        "                'confidence': float(conf),\n",
        "                'bbox': [int(x1), int(y1), int(x2), int(y2)]\n",
        "            })\n",
        "\n",
        "    # Create catalog with counts\n",
        "    object_counts = Counter([d['class'] for d in detections])\n",
        "\n",
        "    # Create DataFrame for easy viewing\n",
        "    catalog_df = pd.DataFrame([\n",
        "        {'Object': obj, 'Count': count}\n",
        "        for obj, count in object_counts.most_common()\n",
        "    ])\n",
        "\n",
        "    return detections, catalog_df, image_rgb\n",
        "\n",
        "print(\"‚úÖ Detection function ready!\")"
      ],
      "metadata": {
        "id": "54VfZmv_b4nP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================\n",
        "# STEP 5: Visualization Function\n",
        "# =====================================\n",
        "def visualize_detections(image_rgb, detections, catalog_df):\n",
        "    \"\"\"\n",
        "    Visualize detected objects with bounding boxes and show catalog.\n",
        "    \"\"\"\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 8))\n",
        "\n",
        "    # Draw bounding boxes\n",
        "    img_with_boxes = image_rgb.copy()\n",
        "    for det in detections:\n",
        "        x1, y1, x2, y2 = det['bbox']\n",
        "        cv2.rectangle(img_with_boxes, (x1, y1), (x2, y2), (0, 255, 0), 3)\n",
        "        label = f\"{det['class']} {det['confidence']:.2f}\"\n",
        "        cv2.putText(img_with_boxes, label, (x1, y1-10),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
        "\n",
        "    # Show image\n",
        "    ax1.imshow(img_with_boxes)\n",
        "    ax1.set_title(f'Detected Objects (Total: {len(detections)})', fontsize=16)\n",
        "    ax1.axis('off')\n",
        "\n",
        "    # Show catalog as table\n",
        "    ax2.axis('tight')\n",
        "    ax2.axis('off')\n",
        "    table = ax2.table(cellText=catalog_df.values,\n",
        "                      colLabels=catalog_df.columns,\n",
        "                      cellLoc='center',\n",
        "                      loc='center')\n",
        "    table.auto_set_font_size(False)\n",
        "    table.set_fontsize(12)\n",
        "    table.scale(1, 2)\n",
        "    ax2.set_title('Object Catalog', fontsize=16)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    print(f\"\\n‚úÖ Found {len(detections)} objects!\")\n",
        "    print(f\"\\nüìä Object Summary:\")\n",
        "    print(catalog_df.to_string(index=False))\n",
        "\n",
        "print(\"‚úÖ Visualization function ready!\")"
      ],
      "metadata": {
        "id": "aneejEuob-2B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================\n",
        "# STEP 6: Example Usage\n",
        "# =====================================\n",
        "# Upload your image and run detection\n",
        "\n",
        "# Example: Upload an image of a messy room\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Get the uploaded image path\n",
        "image_path = list(uploaded.keys())[0]\n",
        "\n",
        "print(f\"‚úÖ Image uploaded: {image_path}\")\n",
        "print(\"\\nüîç Running object detection...\\n\")\n",
        "\n",
        "# Run detection and cataloging\n",
        "detections, catalog, image_rgb = detect_and_catalog_objects(image_path, confidence_threshold=0.25)\n",
        "\n",
        "# Visualize results\n",
        "visualize_detections(image_rgb, detections, catalog)\n",
        "\n",
        "# Save catalog to CSV\n",
        "catalog.to_csv('object_catalog.csv', index=False)\n",
        "print(\"\\nüíæ Catalog saved to 'object_catalog.csv'\")"
      ],
      "metadata": {
        "id": "ONRWerqjcF0z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================\n",
        "# NEXT STEPS: Build Your Complete Pipeline\n",
        "# =====================================\n",
        "\n",
        "print(\"\"\"\n",
        "üöÄ CONGRATULATIONS! You've set up the foundation!\n",
        "\n",
        "üìå NEXT STEPS FOR YOUR KID'S ROOM CLEANUP APP:\n",
        "\n",
        "1Ô∏è‚É£ FINE-TUNE FOR TOY DETECTION:\n",
        "   - Collect 100-200 photos of messy kids' rooms\n",
        "   - Label them using Roboflow: https://roboflow.com\n",
        "   - Train a custom YOLOv8 model on toy categories:\n",
        "     * Dolls, action figures, books, blocks, cars, etc.\n",
        "   - Use: model.train(data='your_dataset.yaml', epochs=100)\n",
        "\n",
        "2Ô∏è‚É£ ADD CARTOON/GAME STYLE TRANSFER:\n",
        "   - Install: !pip install diffusers transformers\n",
        "   - Use Stable Diffusion ControlNet or American Cartoon LoRA\n",
        "   - Models to try:\n",
        "     * Kontext-Style/American_Cartoon_lora\n",
        "     * sd-dreambooth-library/smiling-friendly-kids-cartoon\n",
        "\n",
        "3Ô∏è‚É£ IMPLEMENT OBJECT REMOVAL/INPAINTING:\n",
        "   - Install: !pip install lama-cleaner\n",
        "   - Use LaMa or Stable Diffusion Inpainting\n",
        "   - Mask detected objects and inpaint background\n",
        "\n",
        "4Ô∏è‚É£ CREATE INTERACTIVE UI:\n",
        "   - Use Gradio or Streamlit for web interface\n",
        "   - Add drag-and-drop for detected objects\n",
        "   - Create game mechanics (points for cleanup)\n",
        "\n",
        "5Ô∏è‚É£ BUILD MOBILE APP (Flutter/React Native):\n",
        "   - Use camera to take photos\n",
        "   - Send to your API for detection\n",
        "   - Display cartoon version with interactive objects\n",
        "   - Add physics-based dragging (like Toca Boca)\n",
        "\n",
        "üìö RESOURCES:\n",
        "- YOLOv8 Docs: https://docs.ultralytics.com\n",
        "- Roboflow: https://roboflow.com\n",
        "- Hugging Face Spaces: https://huggingface.co/spaces\n",
        "- SAM (Segment Anything): https://github.com/facebookresearch/segment-anything\n",
        "- Label Studio: https://labelstud.io\n",
        "\n",
        "üë®‚Äçüíª TIPS FOR YOUR 8-YEAR-OLD APP:\n",
        "- Use bright colors and big buttons\n",
        "- Add sound effects for each action\n",
        "- Reward system (stars/badges)\n",
        "- Before/after comparison feature\n",
        "- Parent dashboard for tracking progress\n",
        "\n",
        "‚úÖ This notebook gives you the FOUNDATION.\n",
        "üõ†Ô∏è Now customize it for your specific use case!\n",
        "\"\"\")\n",
        "\n",
        "print(\"\\nüéâ Ready to detect objects in messy rooms! Upload an image above to test.\")"
      ],
      "metadata": {
        "id": "qFBdsToXcMA7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gEXt_H_ibo06"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}